---
title: "R Notebook: Analyse LGT candidates"
output: html_notebook
---


## TODO
- group by start/end - done -
- plot by large candidate -done -
- include noAnt - done -
- set thresholds for evaluation of candidates - done -
- Include read counts for stLFR assembled genomes

```{r}
library(ggplot2)
library(data.table)
library(dplyr)
```

# Load all good candidates for all GAGA species (1st filter: Take only good candidates from both databases)

Load all tsv files for the different GAGA ids in a list of data frames.
```{r}
#tsv2load<-"/Users/lukas/sciebo/Projects/LGT/results/GAGA.LGT/*/results/*.*.lgt.good.candidates.tsv"
#tsv2load<-"/Users/Janina/sciebo/GAGA.LGT/*/results/*.*.lgt.good.candidates.tsv"
tsv2load<-"/global/scratch2/j_rink02/master/lgt/0_data/*/results/*.*.lgt.good.candidates.tsv"
dataFiles <- lapply(Sys.glob(tsv2load), read.csv,sep="\t")
```

# add the name
Add the GAGA id as a name to the different list elements.
Add the database origin as a name to the different list elements.
Set the GAGA-id and database origin separated with a "." as a name for each element of the list "dataFiles".
Each element in the list is one genome, either from the noAnt or the eukaryotic database including the candidates.
```{r}
ids<-gsub(".*/(.+-[0-9]+)\\..+.lgt.good.candidates.tsv","\\1",Sys.glob(tsv2load))
type<-gsub(".*/(.+-[0-9]+)\\.(.+).lgt.good.candidates.tsv","\\2",Sys.glob(tsv2load))
names(dataFiles)<-paste(ids,type,sep=".")
```


# Combine all GAGA ids
Combine tsv files from all GAGA ids in the large list element ("dataFiles") to one big data frame ("df").
```{r}

df<-rbindlist(dataFiles,idcol = T, fill=TRUE) #the fill=TRUE option fills missing columns
```

The unfiltered df containes 13664 candidates from all 162 selected genomes together.
Each row in the dataframe represents one candidate.
```{r}
head(df)
```


# Add scaffold length for every genome
1. Add the scaffolds with their lengths for every genome from the file "genome.file".
2. Create a large dataframe with scaffold length information for every genome called "dscf"
3. Merge the scaffold information together with the information for the LGTs
```{r}
#data2load<-"/Users/lukas/sciebo/Projects/LGT/results/GAGA.LGT/*/results/genome.file"
#data2load<-"/Users/Janina/sciebo/GAGA.LGT/*/results/genome.file"  # load data from all genome.files
data2load<-"/global/scratch2/j_rink02/master/lgt/0_data/*/results/genome.file"  # load data from all genome.files
genomeFiles <- lapply(Sys.glob(data2load), read.csv,sep="\t",header=F) # create large list of all genome.files

# Create a large df with information on scaffold number and length for every genome
genome_ids<-gsub(".*\\/(.*)\\/results\\/genome.file","\\1",Sys.glob(data2load))
names(genomeFiles)<-paste(genome_ids)

dscf<-rbindlist(genomeFiles,idcol = T)

colnames(dscf)
names(dscf)[2]<-"cand.scaffold" #rename the second column of dscf to merge later by this column
names(dscf)[1]<-"GAGA_id"

df$GAGA_id<-gsub("\\..*","",df$.id) #separate the first row of df to merge by column "GAGA_id"


# Merge dscf together with the information for every LGT candidate from df
df<-left_join(df, dscf, by = c("GAGA_id","cand.scaffold"))
names(df)[55]<-"scaffold.length"
df$V2<- NULL
head(df)
```

# extract eval
1. Extract the evalue of the best prokaryotic hit (take column "bestProHit". In this column, the evalue is located  
   between other values and will be extracted in the next command).
   Make a new data table (called "bestblasthits"), separating the original column bestProHit into different columns,    with the each value being separated by ";".

2. Add a column called "besteval" to the df, taking only the eval (column V4) from the bestblasthits dataframe.

```{r}
bestblasthits<-read.csv(text=as.character(df$bestProHit),sep = ";",as.is = T,fill = T,blank.lines.skip = F,header=F)
df$besteval<-bestblasthits$V4
```

# add column with length of candidate

```{r}
df$cand.length<-df$cand.end-df$cand.start
```

# Filter candidates based on the number of reads at the LGT boundary, by adding the read count at each boundary
1. Load the .tsv files into R with all good PacBio overlaps (GAGA-id.LGTboundaries.1000bp.good.PacBio.overlap.tsv) in a list of dataframes
```{r}
#For PacBio assembled genomes only:
#reads2load<-"/global/scratch2/j_rink02/master/lgt/0_data/*/results/*.LGTboundaries.1000bp.good.PacBio.overlap.tsv"

# For all genomes:
reads2load<-"/global/scratch2/j_rink02/master/lgt/0_data/*/results/*.LGTboundaries.*.good.*.overlap.tsv"
readFiles <- lapply(Sys.glob(reads2load), read.csv,sep="\t",header=F) # create large list of all read .tsv files
```

2. Add the GAGA id as a name to the different list elements.
Set the GAGA-id as a name for each element of the list "readFiles".
Each element in the list is one genome.
```{r}
# Create a large df with information on the reads in the boundary region for every genome
read_ids<-gsub(".*/(.+-[0-9]+)\\.LGTboundaries.*.good.*.overlap.tsv","\\1",Sys.glob(reads2load))
names(readFiles)<-paste(read_ids)

#Combine tsv files from all GAGA ids in the large list element ("readFiles") to one big data frame ("df_reads").
df_reads<-rbindlist(readFiles,idcol = T)

#Edit the df_reads dataframe
names(df_reads)[2]<-"scaffold" #rename the second column of df_reads to merge later by this column
names(df_reads)[1]<-"GAGA_id" #rename first column to merge later by this column
names(df_reads)[6]<-"reads_start"
names(df_reads)[11]<-"reads_end"
names(df_reads)[3]<-"start-1000or25bp"
names(df_reads)[4]<-"start+1000or25bp"
names(df_reads)[5]<-"cand.locus"
names(df_reads)[8]<-"end-1000or25bp"
names(df_reads)[9]<-"end+1000or25bp"

df_reads$V6 <- NULL
df_reads$V9 <- NULL

df_reads$cand.locus <-gsub(".start","",df_reads$cand.locus)
df_reads$cand.locus <-gsub(":","-",df_reads$cand.locus)
df_reads$cand.locus <-sub("-",":",df_reads$cand.locus)

df_reads$reads_start <- as.numeric(df_reads$reads_start)
df_reads$reads_end <- as.numeric(df_reads$reads_end)
colnames(df_reads)
```

3. Merge the df_reads dataframe together with the df dataframe based on the columns "GAGA-id" and "cand.locus"
```{r}
# Merge df_reads together with the information for every LGT candidate from df
df<-left_join(df, df_reads, by = c("GAGA_id","cand.locus"))
df$scaffold.y <- NULL
df$scaffold.x <- NULL
head(df)
```

# extract broad locus start and stop
To cluster candidates in one close region together and view them as one single LGT, take the broad locus.

1. The broad locus (columns "scaffold", start","end" or summarized together in column "locus" of df) clusters all
   candidates within +/- 20kb region together and assigns them the same start and stop codon. Thereby, single
   candidates can be grouped by the same start and stop codon in the broad locus region.
   Separate the column "locus" from the df into scaffold (V1), start (V2) and end (V3) in the new dataframe "loci".

2. Add a column called "locus.start", "locus.end" and "locus.length" to the df, taking the now separated columns
   from the new dataframe "loci".
```{r}
loci<-read.csv(text=gsub(":","-",df$locus),sep = "-",as.is = T,fill = T,blank.lines.skip = F,header=F)
df$locus.start<-loci$V2
df$locus.end<-loci$V3
df$locus.length<-df$locus.end-df$locus.start
```

# Plot overview plots
plot histograms of different metrics to see how they are distributed.

```{r}
# gc-content
ggplot(df, aes(x=gc)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# entropy (ce)
ggplot(df, aes(x=ce)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# ct4
ggplot(df, aes(x=ct4)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# ct6
ggplot(df, aes(x=ct6)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# length of broad locus
ggplot(df, aes(x=locus.length)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# length of candidate
ggplot(df, aes(x=cand.length)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# log of best e-value
df$log.besteval<- -log(df$besteval,10)
df$log.besteval[df$log.besteval==Inf]<-max(df$log.besteval[df$log.besteval!=Inf])+1
ggplot(df, aes(x=df$log.besteval)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# BitDiffSum
ggplot(df, aes(x=BitDiffSum)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# Reads at the start of the LGT
ggplot(df, aes(x=reads_start)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()

# Reads at the end of the LGT
ggplot(df, aes(x=reads_end)) +
  geom_histogram(fill="red", alpha=0.5, position="identity")+theme_classic()
```


# Filter the candidate dataset to exclude false-positives and missassemblies

Filter by evalue (evalue > 1e-25), ct4 (ct4>0.25), ce (ce>1.5), BitDiffSum (BitDiffSum>150) and the length of the candidate (length>100)
```{r}
dfFilter<-subset(df,log.besteval>25 & ct4>0.25 & ce>1.5 & BitDiffSum>150 & cand.end-cand.start>100)
df_eval_Filter<-subset(df,log.besteval>25)
df_ct4_Filter<-subset(df,ct4>0.25)
df_ce_Filter<-subset(df,ce>1.5)
df_BitDiffSum_Filter<-subset(df,BitDiffSum>150)
df_length_Filter<-subset(df,cand.end-cand.start>100)
```
Filtering by the above criteria reduces the number of candidates to 5355 candidates (originally: 13664) in all 162 genomes (dfFilter dataframe).

# Save all outfiltered candidates for a re-evalution later
```{r}
# Save all outfiltered candidates in separate dataframes, to have a look at them later & check the quality later manually
df_outfiltered_eval<-subset(df,log.besteval<=25)
df_outfiltered_ct4<-subset(df,ct4<=0.25)
df_outfiltered_ce<-subset(df,ce<=1.5)
df_outfiltered_BitDiffSum<-subset(df,BitDiffSum<=150)
df_outfiltered_length<-subset(df,cand.end-cand.start<=100)

write.table(df_outfiltered_eval,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.eval.outfiltered.tsv",sep="\t",quote = F,row.names = F)
write.table(df_outfiltered_ct4,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.ct4.outfiltered.tsv",sep="\t",quote = F,row.names = F)
write.table(df_outfiltered_ce,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.ce.outfiltered.tsv",sep="\t",quote = F,row.names = F)
write.table(df_outfiltered_BitDiffSum,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.BitDiffSum.outfiltered.tsv",sep="\t",quote = F,row.names = F)
write.table(df_outfiltered_length,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.length.outfiltered.tsv",sep="\t",quote = F,row.names = F)
```


#Filter out candidates at beginning of scaffold
Remove anything at the beginning of a scaffold within the first 1000 bp.
These are more likely to be misassemblies.
```{r}
dfFilter1<-subset(dfFilter,cand.start > 1000)

df_outfiltered_scaffold_start<-subset(dfFilter, cand.start < 1000)

#write.table(df_outfiltered_scaffold_start,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.scaffold_start.outfiltered.tsv",sep="\t",quote = F,row.names = F)
```

Filtering by the above criteria reduces the number of candidates further to 5173 candidates (dfFilter1 dataframe).

# Filter out candidates at end of scaffold
Remove anything at the end of a scaffold within the last 1000 bp.
These are more likely to be misassemblies.
```{r}
# Filter the dataframe to remove candidates at the end of the scaffold       
dfFilter2<-subset(dfFilter1, cand.end < scaffold.length-1000)

df_outfiltered_scaffold_end<-subset(dfFilter1, cand.end > scaffold.length-1000)

#write.table(df_outfiltered_scaffold_end,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.scaffold_end.outfiltered.tsv",sep="\t",quote = F,row.names = F)
```
This further reduces the number of candidates to 5081 possible LGTs (dfFilter2 dataframe).

# Filter candidates based on the number of reads
4. Filter out candidates with zero or only one read at the start (left boundary) and zero or only 1 read at the end (right boundary) of the LGT boundaries. Boundaries, which do not contain any reads, are no real LGTs incorporated into the ant genome, because no read is overlapping the ant DNA and the bacterial DNA.
```{r}
# Filter the dataframe to remove candidates with zero reads at the boundaries
dfFilter3<-subset(dfFilter2, reads_start > 1 & reads_end > 1 | is.na(reads_start & reads_end)) #keep rows where the read count is not available

df_outfiltered_reads<-subset(dfFilter2, reads_start < 2 & reads_end < 2)

write.table(df_outfiltered_reads,"/global/scratch2/j_rink02/master/lgt/2_analysis/lgt_filtering/GAGA.LGT.reads.outfiltered.tsv",sep="\t",quote = F,row.names = F)
```

This further reduces the number of candidates to 4785 possible LGTs (dfFilter3 dataframe).

# Summarize candidates in close proximity into one larger locus
One row per broad start/stop coordinate

## required libraries
```{r}
library(dplyr)
library(ggrepel)
```

1. Create a data frame that has in each row one larger locus (often containing several lgt candidates).
```{r}
# keep one row per larger locus and paste together all the info for the different LGT candidates contained in this locus

## https://stackoverflow.com/questions/40033625/concatenating-all-rows-within-a-group-using-dplyr/40033725
dfC <- dplyr::group_by(df, locus) %>%
       dplyr::summarise_each(funs(paste(unique(.), collapse = ";")))

# filter this by locus dataframe to only keep loci that have at least one good candidate (i.e. that was contained in the dfFilter3 dataframe)
dfC.new.filtered<-subset(dfC,locus %in% unique(dfFilter3$locus),select=c(locus,.id,cand.locus,cand.start,cand.end,bestProHit,BitDiffSum,cand.scaffold,start,end,gc,gcs,ce,reads_start,reads_end))

# save data frame to file
#write.table(dfC.filtered,"/Users/lukas/sciebo/Projects/LGT/results/GAGA.LGT.filtered.tsv",sep="\t",quote = F,row.names = F)
write.table(dfC.new.filtered,"/global/scratch2/j_rink02/master/lgt/2_analysis/GAGA.LGT.162.new.filtered.tsv",sep="\t",quote = F,row.names = F)

# for plotting
# split the unfiltered large df dataframe by "locus" into a list of dataframes (one list element per locus)
dfSplit<-split(df,f=paste(df$.id,df$locus,sep="."))

# filter the list of dataframes to only retain those that contain a LGT from the dfFilter3 dataframe
dfSplit.filtered<-dfSplit[unique(paste(dfFilter3$.id,dfFilter3$locus,sep="."))]

```
Merging candidates in close proximity together and filtering by the above criteria to only obtain candidates which are also in the dfFilter3 dataframe reduces the number of candidates further to 1148 candidates in all 162 genomes (dfC.new.filtered dataframe 1148 candidates remaining).

Note: The filtered.tsv file only contains candidates, which remain after filtering, but the simple plots created by the above commands contain all candidates in this region, even if they would have been filtered out before.

# Plot each locus

```{r}
# Define a function containing a ggplot command. This function will be applied to each element of dfSplit.filtered (the list of dataframes)
plotLGTlocus<-function(locusData){
    locusData$logeval<- -log(locusData$besteval,10)
    locusData$logeval[!is.finite(locusData$logeval)]<- 350
    locusData$species<-substr(gsub(".*;","",locusData$bestProHit),1,20)
    ggplotLGT<-ggplot(locusData)+
          geom_rect(aes(xmin=cand.start,xmax=cand.end,ymin=1,ymax=0,fill=logeval),size=0)+
          coord_cartesian(xlim=c(min(locusData$locus.start),max(locusData$locus.end)),ylim=c(0,5))+
          geom_text_repel(
            aes(x=cand.start,y=1,label=species),
            force_pull   = 0, # do not pull toward data points
            nudge_y      = 0.5,
            direction    = "x",
            angle        = 90,
            hjust        = 0,
            segment.size = 0.2,
            max.iter = 1e4, max.time = 1
            )+
          scale_fill_gradient(low="steelblue",high = "red",limits = c(20,350),na.value = "grey90")+
          ggtitle(locusData$.id[1])+
          theme_classic()+
          xlab(locusData$locus[1])+
          guides(y="none")+
          ylab("")+
          theme(legend.position="right")
    return(ggplotLGT)
  }
```

```{r}
# test the plotting function
plotLGTlocus(dfSplit.filtered[[180]])
```


```{r}
# run plotting function over all elements in the dfSplit.filtered list, i.e. over all loci.
list.of.plots<-lapply(dfSplit.filtered,FUN=plotLGTlocus)

# save all plots (adjust path to your system)
#lapply(1:length(list.of.plots), function(i){
      #ggsave(filename=paste0("/Users/lukas/sciebo/Projects/LGT/results/LGT.filtered/",gsub(":","-",names(list.of.plots)[i]),".pdf"), plot=list.of.plots[[i]])
#  })

lapply(1:length(list.of.plots), function(i){
      ggsave(filename=paste0("/global/scratch2/j_rink02/master/lgt/2_analysis/LGT.filtered/",gsub(":","-",names(list.of.plots)[i]),".pdf"), plot=list.of.plots[[i]])
  })
```

# LGT filtering Plot

We want to find out how many genomes containing good candidates remain after each filtering step.
To do this, we will filter each dataframe for the GAGA-id and count the number of unique GAGA-ids:
```{r}
# Original df
s = df$.id
s1 = sapply(strsplit(s, split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(s1)) #[1] 162

#dfFilter
t = dfFilter$.id
t1 = sapply(strsplit(t, split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(t1)) #[1] 142

#dfFilter1
u = dfFilter1$.id
u1= sapply(strsplit(u,split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(u1))#[1] 141

#dfFilter2
v= dfFilter2$.id
v1=sapply(strsplit(v,split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(v1))#[1] 138

#dfFilter3
w= dfFilter3$.id
w1=sapply(strsplit(w,split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(w1))#[1] 134

#dfC.new.filtered
z= dfC.new.filtered$.id
z1=sapply(strsplit(z,split = '.', fixed = TRUE), function(x) (x[1]))
length(unique(z1))#[1] 134
```

# Summary of the LGT filters
Original: df 13664 candidates, 162 genomes
Without any filters; containing only the candidates predicted by the LGT pipeline with 13664 candidates in all 162 genomes. Hereby, all 162 contain at least one predicted candidate (13664 candidates, 162 genomes)

1st filtering step: dfFilter 5355 remaining candidates, 142 genomes
When looking at each filter separately:
Filtered by e-value (>1e-25, removed 7616 candidates)
Filtered by ct4 (ct4 > 0.25, removed 2.646 candidates)
Filtered by ce (ce > 1.5, removed 485 candidates)
Filtered by BitDiffSum (BitDiffSum > 150, removed 4610 candidates)
Filtered by candidate length (length > 100, removed 2209 candidates)

2nd filtering step: dfFilter1 5173 remaining candidates, 141 genomes
Filtering out candidates starting within the first 1000 bp of the scaffold (cand.start >1000 bp, removed 182 candidates)

3rd filtering step: dfFilter2 5081 remaining candidates, 138 genomes
Filtering out all candidates within the last 1000 bp at the end of scaffold(cand.end != scaffold.length - 1000, removed 92 candidates)

4th filtering step: dfFilter3 4785 candidates
Filtering out all candidates with 0 or only 1 read at the boundaries (reads_start & reads_end > 1, removed 251 candidates)

5th filtering step: dfC.new.filtered 1148 candidates
Merging all candidates within 20kb range further reduces the number to 1148 candidate regions.

# Merge the old .tsv file with candidates already evaluated together with the new tsv files based on the newly applied filters.
1. Load the two tsv files into R
```{r}
# Loaded the tsv files into the environment by hand to not lose any data
Evaluated_df <- GAGA.LGT.162.filtered.good.candidates.taxonomy

newlyfiltered_df <- GAGA.LGT.162.new.filtered
```
2. Merge the two dataframes,such that only the newly added candidates need to be evaluated again.
This means, keep all rows from the newlyfiltered_df, but add the information from the evaluated_df (left_join)
```{r}
complete_df <- merge(x=newlyfiltered_df, y =Evaluated_df, by = "locus", all.x = TRUE)
head(complete_df)
```
3. Edit the complete_df to start the manual investigation
```{r}
complete_df$cand.locus.y <- NULL
complete_df$cand.start.y <- NULL
complete_df$cand.end.y <- NULL
complete_df$bestProHit.y <- NULL
complete_df$BitDiffSum.y <- NULL
complete_df$start.y <- NULL
complete_df$end.y <- NULL
complete_df$gc.y <- NULL
complete_df$gcs.y <- NULL
complete_df$ce.y <- NULL
complete_df$.id.y <- NULL

write.table(complete_df,"/global/scratch2/j_rink02/master/lgt/2_analysis/GAGA.LGT.162.evaluation.tsv",sep="\t",quote = F,row.names = F)
```


# Plot the LGT filters
```{r}
# Assign names to x
x <- c("original", "1st_filtering_step", "2nd_filtering_step", "3rd_filtering_step","4th filtering step", "Merging candidate loci", "Manual investigation")
# Assign names to y
y <- c(13664, 5355, 5173, 5081, 4785, 1148, 410)
# Assign names to z
z <- c(162, 142, 141, 138, 134, 134, 0)
# Assign x to "Filtering_step" as column name
# Assign y to "nr_candidates" as column name
# Assign z to "Nr_of_genomes" as column name
filtering_df <- data.frame( "Filtering_step" = x, "Nr_candidates" = y, "Nr_of_genomes" = z)
# Print the data frame
filtering_df
```


```{r}
library(forcats)
library(ggplot2)
library(viridisLite)

p0 <- ggplot(filtering_df, aes(x=reorder(Filtering_step, -Nr_candidates), y=Nr_candidates, fill=Nr_candidates)) +
  geom_bar(stat="identity")+theme_classic()+
  coord_flip()
p0

# flipped version
p1 <- ggplot(filtering_df, aes(x =reorder(Filtering_step, Nr_candidates), y = Nr_candidates)) +
  geom_bar(aes(fill=as.factor(Nr_candidates)), stat="identity", width = 0.4) + theme_classic() +
  geom_text(aes(label=Nr_candidates), hjust=1.3, color = "white", position=position_dodge(width=1.0), size = 3) +
  scale_fill_gradient(low="darkgreen", high ="darkblue") +
  theme(legend.position = "none") +
  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_viridis_d(breaks = rev, direction = -1)+
  scale_y_continuous(position = "right", breaks = seq(0,14000, 2000)) +
  labs(title = "Filtering of predicted LGT candidates", x = NULL, y="Number of candidates")
p1
```
```{r}

#ggsave("LGT_filtering.png", path = "/Users/Janina/Documents/MASTER/Masterarbeit/plots/self_produced")
```

Last changed 2021/10/29
