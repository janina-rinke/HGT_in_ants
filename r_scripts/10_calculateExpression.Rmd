---
title: "Calculate expression of single CDS of LGT regions"
author: "Janina Rinke"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: true
    number_sections: true
    df_print: paged
  pdf_document: default
---
<STYLE TYPE="text/css">
<!--
  td{
    font-family: Arial;
    font-size: 8pt;
    padding:0px;
    cellpadding="0";
    cellspacing="0"
  }
  th {
    font-family: Arial;
    font-size: 8pt;
    height: 20px;
    font-weight: bold;
    text-align: right;
    background-color: #ccccff;
  }
  table {
    border-spacing: 0px;
    border-collapse: collapse;
  }
--->
</STYLE>
---

This script combines the information about all LGT candidates and respective CDS detected by dfast together with the RNAseq mapping expression. The read counts for every single CDS are added to the dataframe and plotted for the candidates. At the end, one CDS-level table and one LGT.locus level table are computed.

```{r global-options, include=FALSE}
# Define the global chunk options
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r libraries}
library(ggplot2)
library(data.table)
library(dplyr)
library(tidyr)
library(purrr)
library(ape)
library(tidyverse)
library(stringr)
library(writexl)
```

## Extract expression from RNAseq mapping files

#### Load the RNAseq mapping files for every LGT candidate into R.
```{r load files}
#Mac Computer:
txt2load<-"/Users/Janina/sciebo/Master.LGTs/RNAseqmapping/*/RNAseq_mapping_count_summary.txt"
#Linux Computer
#txt2load<-"/home/j/j_rink02/sciebo/Master.LGTs/RNAseqmapping/*/RNAseq_mapping_count_summary.txt"
files.to.load<-Sys.glob(txt2load) #Sys.glob() returns all paths to the files based on a wildcard pattern in our file paths
head(files.to.load)
```

Here, `r length(files.to.load)` RNAseq mapping files were loaded. Some candidates did not have RNAseq data, therefore some files are missing.

Save all file paths in a list called dataFiles and re-name the list elements
```{r load files 2}
dataFiles <- lapply(files.to.load,read.delim2,sep = "\t") #lapply function to read all files and save them as dataframes
#MacComputer
names(dataFiles)<-gsub("/Users/Janina/sciebo/Master.LGTs/RNAseqmapping/(.*?)\\.fa.*","\\1",files.to.load) # gsub() selectively replaces multiple occurrences of a text within an R string ("search term", "replacement term",string searched) 
#Linux Computer
#names(dataFiles)<-gsub("/home/j/j_rink02/sciebo/Master.LGTs/RNAseqmapping/(.*?)\\.fa.*","\\1",files.to.load)
```

To check, whether all dataframes have been imported correctly, you can view any element from the list:
```{r check files}
summary(dataFiles[1])
dataFiles[1]
```


```{r load single file}
#dataFiles[["GAGA-0515.Scaffold8.1760778-1761241"]]
#i<-393
txtfile<-dataFiles[[393]]
head(txtfile)
```


#### Calculate the sum of unique reads per CDS (sum of all samples e.g. queens, workers, males) using dplyr
```{r sum-expression single file}
#### For a single file
df<-txtfile %>%                               # Specify data frame
  dplyr::group_by(chr,start,end) %>%          # Specify indicators to group on 
  dplyr::summarise_at(vars(ucount),           # Specify column to summarize based on the group indicators
               list(totalcount = sum))        # Specify function (summarize as a list and save in column "totalcount")

df$locusID<-names(dataFiles)[393]             # Add the name of the LGT by adding a column called "locusID" 
df<-df %>% 
  separate(locusID, sep="\\.", c(".id","locus.scaffold","locus.position")) %>% 
  dplyr::rename(CDS.start=start, CDS.end=end)# Separate the locusID column into .id, scaffold and CDS position

df$chr<-NULL
head(df)
```

```{r sum-expression all}
#### For all files: 
#Define a function and apply function to all files with map()
summarizeExpression <- function(DF) {
  DF %>% 
 dplyr::group_by(chr,start,end) %>%          
 dplyr::summarise_at(vars(ucount),          
               list(totalcount = sum))
}

dataFiles2 <- map(dataFiles,summarizeExpression)

# Add LGT names to all dataframes as a column and separate into single columns with GAGAid, Scaffold and CDS coordinate.
#Check if all locusIDs have the structure {GAGA-id}.{Scaffold}.{start}-{stop}
names(dataFiles2)[grep("\\.1\\.",names(dataFiles2))] 
#Output: 22 Genomes with different structure e.g. "OUT-0001.WHNR01000088.1.32800-34183"

# Re-name these 22 genome names in the new column locusID from XY.1.XY -> XY_1_XY
for (i in seq_along(dataFiles2)) {
  dataFiles2[[i]]$locusID <- gsub("\\.([0-9])\\.","_\\1.",names(dataFiles2)[i])
}

# separate the locusIDs in all files
separateLOCUSID <- function(DF) {
  DF %>% 
  separate(locusID, sep="\\.", c("GAGAid","locus.scaffold","locus.position")) %>% 
  dplyr::rename(CDS.start=start, CDS.end=end)  
}

dataFiles3 <- map(dataFiles2,separateLOCUSID)

for (i in seq_along(dataFiles3)) {
  dataFiles3[[i]]$chr <- NULL
}
```

## Combine information from dfast with RNAseq mapping data
```{r add dfast single file}
# For a single file
df.dfast<-read.csv("/Users/Janina/sciebo/Master.LGTs/dfast/GAGA-0515.Scaffold8.1760778-1761241.fa/genome.gff_mod.gff",sep="\t",header=F)
df.new<-merge(df, df.dfast,by.x=c("locus.scaffold","CDS.start","CDS.end"),by.y=c("V1","V4","V5"),all.x=T,all.y=T)

df.new<-df.new %>%
  dplyr::relocate(".id", .before = "locus.scaffold") %>%
  dplyr::relocate("locus.position", .before = "CDS.start")

# Add product from dfast as a column
df.new$product<-gsub(".*product=(.*?)\\;.*","\\1",df.new$V9)
# Add UniProtID from dfast as a column
df.new$UniProtID<-gsub(".*UniprotKB:UniRef90_(.*?)\\;.*","\\1",df.new$V9)
# Add the predicted bacteria from dfast as a column
df.new$dfastBacteriapredicted<-gsub(".*\\((.*?)\\).*","\\1",df.new$V9)
head(df.new)
```


```{r add dfast all}
# For all files
#gff2load<-"/home/j/j_rink02/sciebo/Master.LGTs/dfast/*/genome.gff_mod.gff"
gff2load<-"/Users/Janina/sciebo/Master.LGTs/dfast/*/genome.gff_mod.gff"
gff.files.to.load<-Sys.glob(gff2load) #Sys.glob() returns all paths to the files based on a wildcard pattern in our file paths
head(gff.files.to.load)

gffs <- lapply(gff.files.to.load,read_tsv,col_names=F,col_types = cols(.default = "c")) #lapply function to read all files and save them as dataframes
names(gffs)<-gsub("/Users/Janina/sciebo/Master.LGTs/dfast/*/(.*?)\\.fa.*","\\1",gff.files.to.load)

# Make a large dataframe (dataFiles3.df) from all GAGA LGTs in the large list element ("dataFiles3")
dataFiles3.df<-bind_rows(dataFiles3,.id="locusID") #The .id option names the first column ("locusID") after the names of the list elements
#Another possibility: df_combined<-rbindlist(dataFiles3,idcol = T, fill=TRUE)

# Make large dataframe (gffs.df) from gff list elements (gffs)
gffs.df<-bind_rows(gffs,.id="locusID") 

# Combine the two large dataframes into one big df (df4) to have all information for the expression + information from dfast
df4<-merge(dataFiles3.df,gffs.df,by.x=c("locusID","CDS.start","CDS.end"),by.y=c("locusID","X4","X5"),all=T)

df4<-df4 %>%
  dplyr::relocate("GAGAid","locus.scaffold","locus.position", .before = "CDS.start") 

# Add product from dfast as a column
df4$product<-gsub(".*product=(.*?)\\;.*","\\1",df4$X9)

# Add UniProtID from dfast as a column
df4$note<-str_extract(df4$X9,"note=.*") 
df4$UniProtID<-str_extract(df4$note,"UniRef90_.*? ")
df4$UniProtID<-gsub(".*UniRef90_","",df4$UniProtID)

# Combine this dataframe later with the LGT.CDS.level dataframe
head(df4)
```

## Add start and stop codons for every CDS.
This can be used to filter for candidates which contain a correct Start and a correct Stop Codon.
```{r add start and stop codons}
# Use df4 to extract the ids matching ids in the start.stop.codons.table (MGA1; MGA2)
df4$CDSid<-gsub("ID=(.*?)\\;.*","\\1",df4$X9)

# Upload the file including the codons and change it to merge it accordingly
CodonsDF<-read.csv("/Users/Janina/sciebo/Master.LGTs/all.start.stop.codons2.tsv", sep="\t", header=F)
CodonsDF$locusID<-gsub("(.*?)\\.fa","\\1",CodonsDF$V1) #make column locusID to group on
CodonsDF$CDSid<-gsub("(.*?) .*","\\1",CodonsDF$V2) #make column CDSid to group on

CodonsDF$startCodon<-word(CodonsDF$V2,4)
CodonsDF$stopCodon<-word(CodonsDF$V2,5)

df4<-merge(df4,CodonsDF,by.x=c("locusID","CDSid"),by.y=c("locusID","CDSid"),all=T)
```

## Summarize CDS-level table to obtain the LGT locus level.
For every LGT candidate region, CDS starts, CDS ends and CDS total counts will be given in summarized columns.
```{r summary CDS level}
# For a single file
df.final<-df.new %>%  
  dplyr::group_by(.id, locus.scaffold, locus.position) %>% 
  dplyr::summarize(CDS.starts = paste0(CDS.start, collapse = ";"),CDS.ends = paste0(CDS.end, collapse = ";"),CDS.totalcounts = paste0(totalcount, collapse = ";"),CDS.products = paste0(product, collapse = ";"),CDS.UniProtIDs = paste0(UniProtID, collapse = ";"),dfast.donor = paste0(dfastBacteriapredicted, collapse = ";")) 

# To extract pid, q_cov_s_cov
#gsub(".*?\\[(.*?)\\].*","\\1",df4$X9)

# Extract some more information for the LGT.locus level dataframe
df5<-df4
df5$cog<-str_extract(df4$note,"COG:.*") 
df5$tigr<-str_extract(df4$note,"TIGR:.*") 
df5$values<-gsub(".*?\\[(.*?)\\].*","\\1",df4$X9)

df5$pid<-str_extract(df5$values,"pid:.*? ") 
df5$pid<-gsub(".*pid:","",df5$pid)
df5$pid<-gsub("%.*","",df5$pid)

df5$q_cov<-str_extract(df5$values,"q_cov:.*?%") 
df5$q_cov<-gsub(".*q_cov:","",df5$q_cov) 
df5$q_cov<-gsub("%","",df5$q_cov) 

df5$s_cov<-str_extract(df5$values,"s_cov:.*?%") 
df5$s_cov<-gsub(".*s_cov:","",df5$s_cov) 
df5$s_cov<-gsub("%","",df5$s_cov) 

df5$Eval<-str_extract(df5$values,"Eval:.*?%") 
df5$Eval<-gsub(".*Eval:","",df5$Eval) 
df5$Eval<-gsub("%","",df5$Eval) 

df5$totalcount<-as.numeric(df5$totalcount)

# For all files
df6<-df5 %>%  
  dplyr::group_by(locusID, GAGAid,locus.scaffold, locus.position) %>% 
  dplyr::summarize(CDS.starts = paste0(CDS.start, collapse = ";"),CDS.ends = paste0(CDS.end, collapse = ";"),CDS.totalcounts = paste0(totalcount, collapse = ";"),CDS.products = paste0(product, collapse = ";"),CDS.UniprotIDs = paste0(UniProtID, collapse = ";"),CDS.cogs = paste0(cog, collapse = ";"),CDS.tigrs = paste0(tigr, collapse = ";"),CDS.pids = paste0(pid, collapse = ";"),CDS.q_covs = paste0(q_cov, collapse = ";"),CDS.s_covs = paste0(s_cov, collapse = ";"),CDS.Eval = paste0(Eval, collapse = ";"),CDS.startCodons = paste0(startCodon, collapse = ";"),CDS.stopCodons = paste0(stopCodon, collapse = ";")) 

# Some candidates did not have a RNAseq summary file, therefore the GAGAid and locus.position is missing here. Here, the information for GAGAid and locus.position need to be added again.
df6 <- df6 %>%
  dplyr::mutate(GAGAid = ifelse(is.na(GAGAid), locusID, GAGAid)) %>%
  dplyr::mutate(locus.scaffold = ifelse(is.na(locus.scaffold), locusID, locus.scaffold)) %>%
  dplyr::mutate(locus.position = ifelse(is.na(locus.position), locusID, locus.position))

df6$GAGAid<-gsub("(.*?)\\..*","\\1",df6$GAGAid) 
df6$locus.scaffold<-gsub(".*\\.(.*?)\\..*","\\1",df6$locus.scaffold) 
df6$locus.position<-gsub(".*\\.(.*?)\\.*","\\1",df6$locus.position) 
head(df6)
```

`r nrow(df6)` LGT candidates had either a dfast gff annotation or RNAseq data available.

## Merge Locus-level expression table with previous information for LGT candidates
```{r load lgts-combined table}
library(readxl)
# Load the LGT table without expression into R
LGTs<-read_excel("/Users/Janina/Documents/MASTER/Masterarbeit/lgt/0_data/GAGA.LGT.LocusLevel.withoutExpression.xlsx")
head(LGTs)

# Add new column locus.position to LGTs df to group based on the locus
LGTs$locus.position<-str_extract(LGTs$cand.locus,":.*") 
LGTs$locus.position<-gsub(":","",LGTs$locus.position)

# Change scaffold in 22 genomes with XY.1.XY to XY_1_XY to group based on scaffold

LGTs.locuslevel.df<-merge(LGTs,df6,by.x=c(".id","locus.position"),by.y=c("GAGAid","locus.position"),all=T)

LGTs.final.df<-LGTs.locuslevel.df %>%
  dplyr::relocate("locusID",.before=".id") %>%
  dplyr::relocate("locus.scaffold",.before="locus.position") %>%
  dplyr::select(-cand.scaffold,-Expression,-Status,-Complete_CDS)

# Save the LGT locus level table including expression and dfast results 
#write_xlsx(LGTs.final.df,"/Users/Janina/Documents/MASTER/Masterarbeit/lgt/0_data/LGTs.LocusLevel.Expression.xlsx")

### To extract the CDS-level dataframe
CDS.final.df<-separate_rows(LGTs.final.df, "CDS.starts", "CDS.ends", "CDS.totalcounts", "CDS.products", "CDS.UniprotIDs", "CDS.cogs", "CDS.tigrs", "CDS.pids", "CDS.q_covs", "CDS.s_covs", "CDS.Eval", "CDS.startCodons","CDS.stopCodons",sep= ";")

# Save the CDS level table including expression and dfast results 
#write_xlsx(CDS.final.df,"/Users/Janina/Documents/MASTER/Masterarbeit/lgt/0_data/LGTs.CDSLevel.Expression.xlsx")
```
`r nrow(CDS.final.df)` CDS sequences were predicted for the 497 candidates in total.


## Completeness check: Summary and analysis of candidates
```{r summary}

# Filter LGT candidates where all CDS are expressed (read cut-off: < 10)
dfExpression<-LGTs.final.df %>%
  dplyr::filter(CDS.totalcounts > 10 & CDS.totalcounts != "NA")

# Filter CDS sequences which are expressed
CDS.final.df$CDS.totalcounts<-as.numeric(CDS.final.df$CDS.totalcounts)

dfCDSexpression<-CDS.final.df %>%
  dplyr::filter(CDS.totalcounts > 10 & CDS.totalcounts != "NA")

# Filter CDS sequences which have "ATG" as start codon and either "TGA", "TAA" or "TGT" as stop codon
dfA<- CDS.final.df %>%
  dplyr::filter(CDS.startCodons == "ATG") %>%
  dplyr::filter(CDS.stopCodons == "TGA" | CDS.stopCodons =="TAA" | CDS.stopCodons == "TGT")

# Filter candidates which have complete Start/Stop Codons (dfA) and s_cov > 70 %
dfA$CDS.s_covs<- as.numeric(dfA$CDS.s_covs)
df.Complete.LGTs <- dfA %>%
  dplyr::filter(CDS.s_covs > 70 & CDS.s_covs != "NA")

# Filter all candidates with protein coding hits
df.proteins<-CDS.final.df %>%
  dplyr::select(locusID, CDS.starts, CDS.ends, CDS.products, CDS.cogs, CDS.tigrs) %>% #create subset df for all proteins
  dplyr::filter(CDS.products != "NA") %>%                 # remove sequences which do not have a predicted protein
  dplyr::filter(CDS.products != "hypothetical protein" | CDS.cogs != "NA" | CDS.tigrs != "NA")

df.proteins$CDS.cogs<-gsub(".*:(.*?)\\[.*","\\1",df.proteins$CDS.cogs)
df.proteins$CDS.tigrs<-gsub(".*:(.*?)\\[.*","\\1",df.proteins$CDS.tigrs)

df.proteins.factor<-df.proteins %>%
  mutate_if(sapply(df.proteins, is.character), as.factor)


sapply(df.proteins.factor, class)
  
# Extract the proteins as single levels and merge the three protein predictions into one df
dfX<-levels(df.proteins.factor$CDS.products)
dfY<-levels(df.proteins.factor$CDS.cogs)
dfZ<-levels(df.proteins.factor$CDS.tigrs)

dfX<-as.data.frame(dfX)
dfY<-as.data.frame(dfY)
dfZ<-as.data.frame(dfZ)

df.prot<-merge(dfX,dfY, by.x="dfX",by.y="dfY", all = TRUE)
df.prot<-merge(df.prot,dfZ,by.x="dfX",by.y="dfZ",all=TRUE)


# Remove NAs and uncharacterized proteins
df.prot<-df.prot %>%
  rename(proteins=dfX) %>%
  dplyr::filter(proteins != "NA") %>%
  dplyr::filter(proteins !="Uncharacterized protein") %>%
  dplyr::filter(proteins !="hypothetical protein")

 
#write.table(df.prot,file="/Users/Janina/Documents/MASTER/Masterarbeit/lgt/0_data/LGTs.proteins.tsv", sep="\t", quote=F)
write.table(df.Complete.LGTs,file="/Users/Janina/Documents/MASTER/Masterarbeit/lgt/0_data/LGTs.complete.before.reAnnotation.tsv", sep="\t", quote=F)
head(df.Complete.LGTs)
```


In summary, `r nrow(df.prot)` proteins were annotated by dfast (UniRef, COG, TIGR summarized) within `r nrow(CDS.final.df)` CDS sequences. From `r nrow(CDS.final.df)` CDS sequences, `r nrow(dfCDSexpression)` CDS were expressed with at least 10 read counts.

`r nrow(dfA)` CDS have a Start Codon at the beginning of their sequence ("ATG") and a Stop Codon ("TGA", "TGT" or "TAA").
Without re-annotation, `r nrow(df.Complete.LGTs)` CDS sequences are complete. All other CDS sequences/LGT need a re-annotation and possible expansion of the LGT region to check whether candidates will obtain completeness after.

## GAGA-0515 expression
Calculate the expression for the different life stages of GAGA-0515

```{r expression GAGA-0515}
#dataFiles[["GAGA-0515.Scaffold8.1760778-1761241"]]
i<-393
G515<-dataFiles[[i]]

# Add a column for the different life stages to calculate the reads separately for every life stage
G515$stage<-gsub(".*Cobs_(.*?)\\_.*","\\1",G515$e_id)

#Calculate the reads for every life stage
G515_df<-G515 %>%                               
  dplyr::group_by(chr,start,end,stage) %>%           
  dplyr::summarise_at(vars(ucount),         
               list(totalcountPerStage = sum)) 
  
# Calculate mean of samples
G515_mean<-G515 %>%
  dplyr::group_by(chr,start,end,stage) %>% 
  dplyr::summarise(avg=round(mean(ucount),1)) # with round() you can specify how many decimal places you want

G515.new<-merge(G515_df, G515_mean,by.x=c("chr","start","end","stage"),by.y=c("chr","start","end","stage"),all.x=T,all.y=T)

# Include the number of samples per stage
G515_sampleCount<-G515 %>%
  dplyr::count(stage) 

# Merge all information together into a final G-0515 expression table
G515.expression<-merge(G515.new, G515_sampleCount,by.x=c("stage"),by.y=c("stage"),all.x=T,all.y=T)

G515.expression$locusID<-names(dataFiles)[393]             # Add the name of the LGT by adding a column called "locusID" 
G515.expression<-G515.expression %>% 
  separate(locusID, sep="\\.", c(".id","locus.scaffold","locus.position")) %>% 
  dplyr::rename(CDS.start=start, CDS.end=end)# Separate the locusID column into .id, scaffold and CDS position

G515.expression<-G515.expression %>%
  dplyr::select(-chr)%>%
  dplyr::relocate("CDS.start","CDS.end","stage","totalcountPerStage","n","avg", .after = "locus.position")

G515.expression

# Save output as a table
#write.table(G515.expression,"/home/j/j_rink02/sciebo/Master.LGTs/dfast/GAGA-0515.Scaffold8.1760778-1761241.fa/G515.expression.tsv",sep="\t",quote = F,row.names = F)
```

